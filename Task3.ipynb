{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "z3Rds1Dzh9Ai"
   },
   "outputs": [],
   "source": [
    "# Use Google Colab GPU in Task3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rpBDbf3niCzy"
   },
   "source": [
    "### Read and Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Uzj9l6TNiA19"
   },
   "outputs": [],
   "source": [
    "traindata = loadmat('train_32x32.mat')\n",
    "testdata = loadmat('test_32x32.mat')\n",
    "x_train = traindata['X']\n",
    "y_train = traindata['y']\n",
    "x_test = testdata['X']\n",
    "y_test = testdata['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "kV3tOHOJiJDt"
   },
   "outputs": [],
   "source": [
    "# y_train,y_test changed to (0,9)\n",
    "y_train = y_train -1\n",
    "y_test = y_test -1\n",
    "\n",
    "# normalize X\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "37HMAspriJMi"
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "#input image dimensions\n",
    "img_rows, img_cols = 32, 32\n",
    "\n",
    "x_train_images = x_train.transpose(3, 0, 1, 2)\n",
    "x_test_images = x_test.transpose(3, 0, 1, 2)\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QY3j8MC9iYEP"
   },
   "source": [
    "### Train convolutional neural network with a base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vAUfZeZViMxh"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation\n",
    "from keras.models import Sequential\n",
    "cnn = Sequential()\n",
    "cnn.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(64, activation='relu'))\n",
    "cnn.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 97532,
     "status": "ok",
     "timestamp": 1524847345529,
     "user": {
      "displayName": "Selina Tang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109686041627228452104"
     },
     "user_tz": 240
    },
    "id": "2YkISOLAiM4-",
    "outputId": "3fc007a6-d9e8-4c55-8b1d-0030fc23f849"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 65931 samples, validate on 7326 samples\n",
      "Epoch 1/10\n",
      "65931/65931 [==============================] - 11s 172us/step - loss: 1.2217 - acc: 0.6102 - val_loss: 0.6680 - val_acc: 0.8070\n",
      "Epoch 2/10\n",
      "65931/65931 [==============================] - 9s 138us/step - loss: 0.6172 - acc: 0.8260 - val_loss: 0.6174 - val_acc: 0.8281\n",
      "Epoch 3/10\n",
      "35712/65931 [===============>..............] - ETA: 3s - loss: 0.5535 - acc: 0.846165931/65931 [==============================] - 9s 138us/step - loss: 0.5436 - acc: 0.8489 - val_loss: 0.5252 - val_acc: 0.8546\n",
      "Epoch 4/10\n",
      "65931/65931 [==============================] - 9s 137us/step - loss: 0.4988 - acc: 0.8619 - val_loss: 0.4944 - val_acc: 0.8628\n",
      "Epoch 5/10\n",
      "65931/65931 [==============================] - 9s 138us/step - loss: 0.4663 - acc: 0.8707 - val_loss: 0.4742 - val_acc: 0.8720\n",
      "Epoch 6/10\n",
      " 5120/65931 [=>............................] - ETA: 7s - loss: 0.4609 - acc: 0.869165931/65931 [==============================] - 9s 138us/step - loss: 0.4410 - acc: 0.8770 - val_loss: 0.4580 - val_acc: 0.8716\n",
      "Epoch 7/10\n",
      "65931/65931 [==============================] - 9s 138us/step - loss: 0.4182 - acc: 0.8821 - val_loss: 0.4514 - val_acc: 0.8748\n",
      "Epoch 8/10\n",
      "63104/65931 [===========================>..] - ETA: 0s - loss: 0.3997 - acc: 0.887765931/65931 [==============================] - 9s 139us/step - loss: 0.4009 - acc: 0.8874 - val_loss: 0.4316 - val_acc: 0.8832\n",
      "Epoch 9/10\n",
      "65931/65931 [==============================] - 9s 138us/step - loss: 0.3835 - acc: 0.8905 - val_loss: 0.4413 - val_acc: 0.8771\n",
      "Epoch 10/10\n",
      "65931/65931 [==============================] - 9s 139us/step - loss: 0.3682 - acc: 0.8953 - val_loss: 0.4345 - val_acc: 0.8791\n",
      " 8832/26032 [=========>....................] - ETA: 2s26032/26032 [==============================] - 4s 137us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.503243366596372, 0.8638982790411801]"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.compile(\"adam\", \"categorical_crossentropy\", metrics=['accuracy'])\n",
    "history_cnn = cnn.fit(x_train_images, y_train,\n",
    "                      batch_size=128, epochs=10, verbose=1, validation_split=.1)\n",
    "cnn.evaluate(x_test_images, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As reported above, the base model contained two convolutional layers with epochs = 10, and got the final validation accuracy of 0.8791 and test accuracy of 0.8639. higher than 0.85."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WsRJmL_tijG9"
   },
   "source": [
    "### Using Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "xhBGdi3LiM8O"
   },
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "cnn_small_bn = Sequential()\n",
    "cnn_small_bn.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 input_shape=input_shape))\n",
    "cnn_small_bn.add(Activation(\"relu\"))\n",
    "cnn_small_bn.add(BatchNormalization())\n",
    "cnn_small_bn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_small_bn.add(Conv2D(32, (3, 3)))\n",
    "cnn_small_bn.add(Activation(\"relu\"))\n",
    "cnn_small_bn.add(BatchNormalization())\n",
    "cnn_small_bn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_small_bn.add(Flatten())\n",
    "cnn_small_bn.add(Dense(64, activation='relu'))\n",
    "cnn_small_bn.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1788
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 608862,
     "status": "ok",
     "timestamp": 1524849522060,
     "user": {
      "displayName": "Selina Tang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109686041627228452104"
     },
     "user_tz": 240
    },
    "id": "qMwdJ8ukiJPc",
    "outputId": "87690d35-fdae-4274-f08f-931b3e83ca56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 65931 samples, validate on 7326 samples\n",
      "Epoch 1/50\n",
      "65931/65931 [==============================] - 13s 197us/step - loss: 0.8242 - acc: 0.7444 - val_loss: 0.5338 - val_acc: 0.8425\n",
      "Epoch 2/50\n",
      "65931/65931 [==============================] - 12s 183us/step - loss: 0.4217 - acc: 0.8754 - val_loss: 0.4457 - val_acc: 0.8698\n",
      "Epoch 3/50\n",
      "15744/65931 [======>.......................] - ETA: 8s - loss: 0.3483 - acc: 0.899865931/65931 [==============================] - 12s 182us/step - loss: 0.3498 - acc: 0.8976 - val_loss: 0.4500 - val_acc: 0.8694\n",
      "Epoch 4/50\n",
      "65931/65931 [==============================] - 12s 184us/step - loss: 0.3038 - acc: 0.9100 - val_loss: 0.4583 - val_acc: 0.8610\n",
      "Epoch 5/50\n",
      "46208/65931 [====================>.........] - ETA: 3s - loss: 0.2709 - acc: 0.919465931/65931 [==============================] - 12s 183us/step - loss: 0.2720 - acc: 0.9185 - val_loss: 0.4157 - val_acc: 0.8802\n",
      "Epoch 6/50\n",
      "65931/65931 [==============================] - 12s 185us/step - loss: 0.2417 - acc: 0.9276 - val_loss: 0.4043 - val_acc: 0.8868\n",
      "Epoch 7/50\n",
      "51200/65931 [======================>.......] - ETA: 2s - loss: 0.2120 - acc: 0.936365931/65931 [==============================] - 12s 184us/step - loss: 0.2169 - acc: 0.9356 - val_loss: 0.4223 - val_acc: 0.8800\n",
      "Epoch 8/50\n",
      "65931/65931 [==============================] - 12s 183us/step - loss: 0.1974 - acc: 0.9413 - val_loss: 0.4692 - val_acc: 0.8711\n",
      "Epoch 9/50\n",
      "52608/65931 [======================>.......] - ETA: 2s - loss: 0.1721 - acc: 0.948165931/65931 [==============================] - 12s 184us/step - loss: 0.1762 - acc: 0.9471 - val_loss: 0.4819 - val_acc: 0.8662\n",
      "Epoch 10/50\n",
      "65931/65931 [==============================] - 12s 184us/step - loss: 0.1582 - acc: 0.9531 - val_loss: 0.4373 - val_acc: 0.8892\n",
      "Epoch 11/50\n",
      "51968/65931 [======================>.......] - ETA: 2s - loss: 0.1463 - acc: 0.956465931/65931 [==============================] - 12s 183us/step - loss: 0.1488 - acc: 0.9551 - val_loss: 0.4480 - val_acc: 0.8830\n",
      "Epoch 12/50\n",
      "65931/65931 [==============================] - 12s 181us/step - loss: 0.1299 - acc: 0.9608 - val_loss: 0.5217 - val_acc: 0.8726\n",
      "Epoch 13/50\n",
      "54912/65931 [=======================>......] - ETA: 1s - loss: 0.1167 - acc: 0.965065931/65931 [==============================] - 12s 184us/step - loss: 0.1205 - acc: 0.9636 - val_loss: 0.5102 - val_acc: 0.8833\n",
      "Epoch 14/50\n",
      "65931/65931 [==============================] - 12s 183us/step - loss: 0.1112 - acc: 0.9664 - val_loss: 0.5546 - val_acc: 0.8778\n",
      "Epoch 15/50\n",
      "53888/65931 [=======================>......] - ETA: 2s - loss: 0.1047 - acc: 0.967665931/65931 [==============================] - 12s 183us/step - loss: 0.1061 - acc: 0.9674 - val_loss: 0.5052 - val_acc: 0.8898\n",
      "Epoch 16/50\n",
      "65931/65931 [==============================] - 12s 183us/step - loss: 0.0909 - acc: 0.9724 - val_loss: 0.5515 - val_acc: 0.8770\n",
      "Epoch 17/50\n",
      "54272/65931 [=======================>......] - ETA: 2s - loss: 0.0846 - acc: 0.974565931/65931 [==============================] - 12s 183us/step - loss: 0.0864 - acc: 0.9736 - val_loss: 0.5484 - val_acc: 0.8881\n",
      "Epoch 18/50\n",
      "65931/65931 [==============================] - 12s 183us/step - loss: 0.0782 - acc: 0.9764 - val_loss: 0.5644 - val_acc: 0.8867\n",
      "Epoch 19/50\n",
      "51840/65931 [======================>.......] - ETA: 2s - loss: 0.0715 - acc: 0.978965931/65931 [==============================] - 12s 182us/step - loss: 0.0753 - acc: 0.9773 - val_loss: 0.6343 - val_acc: 0.8800\n",
      "Epoch 20/50\n",
      "65931/65931 [==============================] - 12s 184us/step - loss: 0.0674 - acc: 0.9794 - val_loss: 0.6343 - val_acc: 0.8778\n",
      "Epoch 21/50\n",
      "52992/65931 [=======================>......] - ETA: 2s - loss: 0.0761 - acc: 0.976465931/65931 [==============================] - 12s 183us/step - loss: 0.0735 - acc: 0.9772 - val_loss: 0.6072 - val_acc: 0.8837\n",
      "Epoch 22/50\n",
      "65931/65931 [==============================] - 12s 182us/step - loss: 0.0543 - acc: 0.9844 - val_loss: 0.6768 - val_acc: 0.8773\n",
      "Epoch 23/50\n",
      "55424/65931 [========================>.....] - ETA: 1s - loss: 0.0543 - acc: 0.983565931/65931 [==============================] - 12s 183us/step - loss: 0.0568 - acc: 0.9825 - val_loss: 0.6297 - val_acc: 0.8853\n",
      "Epoch 24/50\n",
      "65931/65931 [==============================] - 12s 184us/step - loss: 0.0641 - acc: 0.9802 - val_loss: 0.6631 - val_acc: 0.8847\n",
      "Epoch 25/50\n",
      "51840/65931 [======================>.......] - ETA: 2s - loss: 0.0453 - acc: 0.987165931/65931 [==============================] - 12s 184us/step - loss: 0.0470 - acc: 0.9865 - val_loss: 0.6624 - val_acc: 0.8864\n",
      "Epoch 26/50\n",
      "65931/65931 [==============================] - 12s 182us/step - loss: 0.0453 - acc: 0.9872 - val_loss: 0.7103 - val_acc: 0.8852\n",
      "Epoch 27/50\n",
      "51328/65931 [======================>.......] - ETA: 2s - loss: 0.0395 - acc: 0.988965931/65931 [==============================] - 12s 181us/step - loss: 0.0443 - acc: 0.9868 - val_loss: 0.7083 - val_acc: 0.8802\n",
      "Epoch 28/50\n",
      "65931/65931 [==============================] - 12s 182us/step - loss: 0.0448 - acc: 0.9864 - val_loss: 0.7931 - val_acc: 0.8797\n",
      "Epoch 29/50\n",
      "53632/65931 [=======================>......] - ETA: 2s - loss: 0.0513 - acc: 0.984965931/65931 [==============================] - 12s 181us/step - loss: 0.0523 - acc: 0.9842 - val_loss: 0.7357 - val_acc: 0.8856\n",
      "Epoch 30/50\n",
      "65931/65931 [==============================] - 12s 179us/step - loss: 0.0399 - acc: 0.9880 - val_loss: 0.7444 - val_acc: 0.8823\n",
      "Epoch 31/50\n",
      "53888/65931 [=======================>......] - ETA: 2s - loss: 0.0446 - acc: 0.986365931/65931 [==============================] - 12s 181us/step - loss: 0.0443 - acc: 0.9865 - val_loss: 0.7558 - val_acc: 0.8898\n",
      "Epoch 32/50\n",
      "65931/65931 [==============================] - 12s 181us/step - loss: 0.0418 - acc: 0.9878 - val_loss: 0.7631 - val_acc: 0.8792\n",
      "Epoch 33/50\n",
      "56064/65931 [========================>.....] - ETA: 1s - loss: 0.0403 - acc: 0.988265931/65931 [==============================] - 12s 182us/step - loss: 0.0419 - acc: 0.9878 - val_loss: 0.7863 - val_acc: 0.8807\n",
      "Epoch 34/50\n",
      "65931/65931 [==============================] - 12s 181us/step - loss: 0.0333 - acc: 0.9905 - val_loss: 0.7605 - val_acc: 0.8905\n",
      "Epoch 35/50\n",
      "56320/65931 [========================>.....] - ETA: 1s - loss: 0.0301 - acc: 0.991465931/65931 [==============================] - 12s 181us/step - loss: 0.0325 - acc: 0.9905 - val_loss: 0.7891 - val_acc: 0.8856\n",
      "Epoch 36/50\n",
      "65931/65931 [==============================] - 12s 181us/step - loss: 0.0448 - acc: 0.9867 - val_loss: 0.8138 - val_acc: 0.8750\n",
      "Epoch 37/50\n",
      "53760/65931 [=======================>......] - ETA: 2s - loss: 0.0326 - acc: 0.990765931/65931 [==============================] - 12s 183us/step - loss: 0.0323 - acc: 0.9909 - val_loss: 0.8289 - val_acc: 0.8799\n",
      "Epoch 38/50\n",
      "65931/65931 [==============================] - 12s 184us/step - loss: 0.0312 - acc: 0.9910 - val_loss: 0.8234 - val_acc: 0.8800\n",
      "Epoch 39/50\n",
      "51840/65931 [======================>.......] - ETA: 2s - loss: 0.0292 - acc: 0.991865931/65931 [==============================] - 12s 183us/step - loss: 0.0307 - acc: 0.9913 - val_loss: 0.8267 - val_acc: 0.8800\n",
      "Epoch 40/50\n",
      "65931/65931 [==============================] - 12s 182us/step - loss: 0.0323 - acc: 0.9911 - val_loss: 0.8122 - val_acc: 0.8842\n",
      "Epoch 41/50\n",
      "52736/65931 [======================>.......] - ETA: 2s - loss: 0.0331 - acc: 0.990765931/65931 [==============================] - 12s 185us/step - loss: 0.0355 - acc: 0.9896 - val_loss: 0.8367 - val_acc: 0.8853\n",
      "Epoch 42/50\n",
      "65931/65931 [==============================] - 12s 183us/step - loss: 0.0371 - acc: 0.9893 - val_loss: 0.8343 - val_acc: 0.8882\n",
      "Epoch 43/50\n",
      "52096/65931 [======================>.......] - ETA: 2s - loss: 0.0284 - acc: 0.992865931/65931 [==============================] - 12s 183us/step - loss: 0.0270 - acc: 0.9928 - val_loss: 0.8276 - val_acc: 0.8851\n",
      "Epoch 44/50\n",
      "65931/65931 [==============================] - 12s 183us/step - loss: 0.0237 - acc: 0.9941 - val_loss: 0.8595 - val_acc: 0.8862\n",
      "Epoch 45/50\n",
      "50176/65931 [=====================>........] - ETA: 2s - loss: 0.0291 - acc: 0.992365931/65931 [==============================] - 12s 183us/step - loss: 0.0291 - acc: 0.9922 - val_loss: 0.8669 - val_acc: 0.8818\n",
      "Epoch 46/50\n",
      "65931/65931 [==============================] - 12s 183us/step - loss: 0.0362 - acc: 0.9899 - val_loss: 1.0393 - val_acc: 0.8630\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53376/65931 [=======================>......] - ETA: 2s - loss: 0.0571 - acc: 0.984865931/65931 [==============================] - 12s 181us/step - loss: 0.0536 - acc: 0.9855 - val_loss: 0.8538 - val_acc: 0.8817\n",
      "Epoch 48/50\n",
      "65931/65931 [==============================] - 12s 182us/step - loss: 0.0201 - acc: 0.9953 - val_loss: 0.8431 - val_acc: 0.8893\n",
      "Epoch 49/50\n",
      "54656/65931 [=======================>......] - ETA: 1s - loss: 0.0157 - acc: 0.997065931/65931 [==============================] - 12s 183us/step - loss: 0.0160 - acc: 0.9967 - val_loss: 0.8591 - val_acc: 0.8897\n",
      "Epoch 50/50\n",
      "65931/65931 [==============================] - 12s 182us/step - loss: 0.0258 - acc: 0.9930 - val_loss: 0.8580 - val_acc: 0.8863\n",
      "26032/26032 [==============================] - 5s 177us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0841373216244035, 0.8656653349723418]"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_small_bn.compile(\"adam\", \"categorical_crossentropy\", metrics=['accuracy'])\n",
    "history_cnn_small_bn = cnn_small_bn.fit(x_train_images, y_train,\n",
    "                      batch_size=128, epochs=50, verbose=1, validation_split=.1)\n",
    "cnn_small_bn.evaluate(x_test_images, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then we added the Batch Normalization to the base model, and the test accuracy increased to 0.8657."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B2OZhb9uir20"
   },
   "source": [
    "## Complicated Model with Dropout and more epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the following part, we tried two models to improve our test accuracy and used more epochs (e.g. 50).   \n",
    "#### Model 1 used three convolutional layers with Dropout which reached the test accuracy of 0.9061. In model 2, each layer contained two convolutional sublayers and one maxpooling sublayer. It reached the test accuracy of 0.8911.  \n",
    "#### In conclusion, our final test accuracy increased to 0.9061."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "RfikTztXisdy"
   },
   "outputs": [],
   "source": [
    "# three layers with Dropout\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "cnn_bn = Sequential()\n",
    "cnn_bn.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 input_shape=input_shape))\n",
    "cnn_bn.add(Activation(\"relu\"))\n",
    "cnn_bn.add(BatchNormalization())\n",
    "cnn_bn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_bn.add(Conv2D(32, (3, 3)))\n",
    "cnn_bn.add(Activation(\"relu\"))\n",
    "cnn_bn.add(BatchNormalization())\n",
    "cnn_bn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_bn.add(Conv2D(32, (3, 3)))\n",
    "cnn_bn.add(Activation(\"relu\"))\n",
    "cnn_bn.add(BatchNormalization())\n",
    "cnn_bn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_bn.add(Flatten())\n",
    "cnn_bn.add(Dense(64, activation='relu'))\n",
    "cnn_bn.add(Dropout(0.5))\n",
    "cnn_bn.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1788
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 681496,
     "status": "ok",
     "timestamp": 1524848155438,
     "user": {
      "displayName": "Selina Tang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109686041627228452104"
     },
     "user_tz": 240
    },
    "id": "T1ZOsMFDi0vH",
    "outputId": "8f821e9b-cab2-49bc-e28d-645122871d8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 65931 samples, validate on 7326 samples\n",
      "Epoch 1/50\n",
      "65931/65931 [==============================] - 14s 218us/step - loss: 1.3335 - acc: 0.5621 - val_loss: 0.6467 - val_acc: 0.8008\n",
      "Epoch 2/50\n",
      "65931/65931 [==============================] - 14s 205us/step - loss: 0.6892 - acc: 0.7893 - val_loss: 0.5428 - val_acc: 0.8310\n",
      "Epoch 3/50\n",
      " 5760/65931 [=>............................] - ETA: 11s - loss: 0.6220 - acc: 0.809265931/65931 [==============================] - 14s 205us/step - loss: 0.5660 - acc: 0.8275 - val_loss: 0.5236 - val_acc: 0.8402\n",
      "Epoch 4/50\n",
      "65931/65931 [==============================] - 13s 203us/step - loss: 0.5046 - acc: 0.8499 - val_loss: 0.4194 - val_acc: 0.8735\n",
      "Epoch 5/50\n",
      "31616/65931 [=============>................] - ETA: 6s - loss: 0.4744 - acc: 0.860665931/65931 [==============================] - 13s 204us/step - loss: 0.4661 - acc: 0.8623 - val_loss: 0.4018 - val_acc: 0.8797\n",
      "Epoch 6/50\n",
      "65931/65931 [==============================] - 14s 207us/step - loss: 0.4371 - acc: 0.8713 - val_loss: 0.4276 - val_acc: 0.8701\n",
      "Epoch 7/50\n",
      "36224/65931 [===============>..............] - ETA: 5s - loss: 0.4181 - acc: 0.876465931/65931 [==============================] - 14s 206us/step - loss: 0.4163 - acc: 0.8775 - val_loss: 0.3634 - val_acc: 0.8937\n",
      "Epoch 8/50\n",
      "65931/65931 [==============================] - 14s 206us/step - loss: 0.3905 - acc: 0.8844 - val_loss: 0.3562 - val_acc: 0.8969\n",
      "Epoch 9/50\n",
      "37632/65931 [================>.............] - ETA: 5s - loss: 0.3705 - acc: 0.888165931/65931 [==============================] - 13s 203us/step - loss: 0.3784 - acc: 0.8869 - val_loss: 0.3892 - val_acc: 0.8796\n",
      "Epoch 10/50\n",
      "65931/65931 [==============================] - 14s 207us/step - loss: 0.3721 - acc: 0.8894 - val_loss: 0.3657 - val_acc: 0.8897\n",
      "Epoch 11/50\n",
      "35968/65931 [===============>..............] - ETA: 5s - loss: 0.3536 - acc: 0.894765931/65931 [==============================] - 14s 205us/step - loss: 0.3620 - acc: 0.8928 - val_loss: 0.3377 - val_acc: 0.8999\n",
      "Epoch 12/50\n",
      "65931/65931 [==============================] - 14s 205us/step - loss: 0.3502 - acc: 0.8965 - val_loss: 0.3588 - val_acc: 0.8954\n",
      "Epoch 13/50\n",
      "42880/65931 [==================>...........] - ETA: 4s - loss: 0.3341 - acc: 0.901865931/65931 [==============================] - 13s 202us/step - loss: 0.3397 - acc: 0.9008 - val_loss: 0.3593 - val_acc: 0.8960\n",
      "Epoch 14/50\n",
      "65931/65931 [==============================] - 14s 206us/step - loss: 0.3383 - acc: 0.9011 - val_loss: 0.3423 - val_acc: 0.8997\n",
      "Epoch 15/50\n",
      "36608/65931 [===============>..............] - ETA: 5s - loss: 0.3219 - acc: 0.904865931/65931 [==============================] - 14s 205us/step - loss: 0.3282 - acc: 0.9034 - val_loss: 0.3213 - val_acc: 0.9040\n",
      "Epoch 16/50\n",
      "65931/65931 [==============================] - 13s 204us/step - loss: 0.3215 - acc: 0.9059 - val_loss: 0.3619 - val_acc: 0.8898\n",
      "Epoch 17/50\n",
      "37504/65931 [================>.............] - ETA: 5s - loss: 0.3198 - acc: 0.907365931/65931 [==============================] - 13s 204us/step - loss: 0.3203 - acc: 0.9066 - val_loss: 0.3252 - val_acc: 0.9040\n",
      "Epoch 18/50\n",
      "65931/65931 [==============================] - 13s 201us/step - loss: 0.3141 - acc: 0.9074 - val_loss: 0.3451 - val_acc: 0.8967\n",
      "Epoch 19/50\n",
      "38656/65931 [================>.............] - ETA: 5s - loss: 0.3072 - acc: 0.910065931/65931 [==============================] - 14s 208us/step - loss: 0.3095 - acc: 0.9088 - val_loss: 0.3608 - val_acc: 0.8883\n",
      "Epoch 20/50\n",
      "65931/65931 [==============================] - 14s 205us/step - loss: 0.3034 - acc: 0.9102 - val_loss: 0.3303 - val_acc: 0.9043\n",
      "Epoch 21/50\n",
      "38528/65931 [================>.............] - ETA: 5s - loss: 0.2957 - acc: 0.911565931/65931 [==============================] - 14s 205us/step - loss: 0.3002 - acc: 0.9110 - val_loss: 0.3452 - val_acc: 0.8994\n",
      "Epoch 22/50\n",
      "65931/65931 [==============================] - 14s 206us/step - loss: 0.2996 - acc: 0.9115 - val_loss: 0.3345 - val_acc: 0.9050\n",
      "Epoch 23/50\n",
      "38016/65931 [================>.............] - ETA: 5s - loss: 0.3013 - acc: 0.910565931/65931 [==============================] - 14s 206us/step - loss: 0.2967 - acc: 0.9114 - val_loss: 0.3295 - val_acc: 0.9077\n",
      "Epoch 24/50\n",
      "65931/65931 [==============================] - 14s 206us/step - loss: 0.2891 - acc: 0.9146 - val_loss: 0.3280 - val_acc: 0.9075\n",
      "Epoch 25/50\n",
      "37504/65931 [================>.............] - ETA: 5s - loss: 0.2862 - acc: 0.915965931/65931 [==============================] - 13s 205us/step - loss: 0.2889 - acc: 0.9148 - val_loss: 0.3624 - val_acc: 0.8980\n",
      "Epoch 26/50\n",
      "65931/65931 [==============================] - 14s 206us/step - loss: 0.2803 - acc: 0.9174 - val_loss: 0.3399 - val_acc: 0.9034\n",
      "Epoch 27/50\n",
      "36864/65931 [===============>..............] - ETA: 5s - loss: 0.2759 - acc: 0.916965931/65931 [==============================] - 13s 203us/step - loss: 0.2805 - acc: 0.9170 - val_loss: 0.3227 - val_acc: 0.9099\n",
      "Epoch 28/50\n",
      "65931/65931 [==============================] - 13s 204us/step - loss: 0.2776 - acc: 0.9173 - val_loss: 0.3457 - val_acc: 0.9040\n",
      "Epoch 29/50\n",
      "38016/65931 [================>.............] - ETA: 5s - loss: 0.2778 - acc: 0.919065931/65931 [==============================] - 14s 207us/step - loss: 0.2754 - acc: 0.9190 - val_loss: 0.3222 - val_acc: 0.9091\n",
      "Epoch 30/50\n",
      "65931/65931 [==============================] - 14s 205us/step - loss: 0.2732 - acc: 0.9199 - val_loss: 0.3347 - val_acc: 0.9064\n",
      "Epoch 31/50\n",
      "37760/65931 [================>.............] - ETA: 5s - loss: 0.2670 - acc: 0.920965931/65931 [==============================] - 13s 204us/step - loss: 0.2707 - acc: 0.9196 - val_loss: 0.3356 - val_acc: 0.9047\n",
      "Epoch 32/50\n",
      "65931/65931 [==============================] - 13s 203us/step - loss: 0.2655 - acc: 0.9205 - val_loss: 0.3382 - val_acc: 0.9068\n",
      "Epoch 33/50\n",
      "39680/65931 [=================>............] - ETA: 5s - loss: 0.2676 - acc: 0.921265931/65931 [==============================] - 13s 203us/step - loss: 0.2670 - acc: 0.9208 - val_loss: 0.3260 - val_acc: 0.9058\n",
      "Epoch 34/50\n",
      "65931/65931 [==============================] - 13s 204us/step - loss: 0.2585 - acc: 0.9214 - val_loss: 0.3406 - val_acc: 0.9057\n",
      "Epoch 35/50\n",
      "38656/65931 [================>.............] - ETA: 5s - loss: 0.2512 - acc: 0.922365931/65931 [==============================] - 13s 203us/step - loss: 0.2589 - acc: 0.9222 - val_loss: 0.3621 - val_acc: 0.8982\n",
      "Epoch 36/50\n",
      "65931/65931 [==============================] - 14s 206us/step - loss: 0.2630 - acc: 0.9214 - val_loss: 0.3455 - val_acc: 0.9039\n",
      "Epoch 37/50\n",
      "36480/65931 [===============>..............] - ETA: 5s - loss: 0.2458 - acc: 0.925565931/65931 [==============================] - 14s 207us/step - loss: 0.2548 - acc: 0.9234 - val_loss: 0.3369 - val_acc: 0.9044\n",
      "Epoch 38/50\n",
      "65931/65931 [==============================] - 13s 203us/step - loss: 0.2555 - acc: 0.9231 - val_loss: 0.3451 - val_acc: 0.9054\n",
      "Epoch 39/50\n",
      "37888/65931 [================>.............] - ETA: 5s - loss: 0.2526 - acc: 0.923065931/65931 [==============================] - 14s 206us/step - loss: 0.2564 - acc: 0.9223 - val_loss: 0.3364 - val_acc: 0.9079\n",
      "Epoch 40/50\n",
      "65931/65931 [==============================] - 14s 205us/step - loss: 0.2534 - acc: 0.9241 - val_loss: 0.3256 - val_acc: 0.9120\n",
      "Epoch 41/50\n",
      "39168/65931 [================>.............] - ETA: 5s - loss: 0.2467 - acc: 0.925965931/65931 [==============================] - 14s 205us/step - loss: 0.2479 - acc: 0.9261 - val_loss: 0.3392 - val_acc: 0.9079\n",
      "Epoch 42/50\n",
      "65931/65931 [==============================] - 14s 205us/step - loss: 0.2479 - acc: 0.9254 - val_loss: 0.3340 - val_acc: 0.9084\n",
      "Epoch 43/50\n",
      "38912/65931 [================>.............] - ETA: 5s - loss: 0.2460 - acc: 0.925965931/65931 [==============================] - 13s 204us/step - loss: 0.2441 - acc: 0.9265 - val_loss: 0.3408 - val_acc: 0.9087\n",
      "Epoch 44/50\n",
      "65931/65931 [==============================] - 13s 204us/step - loss: 0.2444 - acc: 0.9268 - val_loss: 0.3490 - val_acc: 0.9070\n",
      "Epoch 45/50\n",
      "39936/65931 [=================>............] - ETA: 5s - loss: 0.2408 - acc: 0.927265931/65931 [==============================] - 13s 203us/step - loss: 0.2414 - acc: 0.9268 - val_loss: 0.3348 - val_acc: 0.9091\n",
      "Epoch 46/50\n",
      "65931/65931 [==============================] - 14s 205us/step - loss: 0.2418 - acc: 0.9277 - val_loss: 0.3497 - val_acc: 0.9099\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39168/65931 [================>.............] - ETA: 5s - loss: 0.2353 - acc: 0.929065931/65931 [==============================] - 14s 205us/step - loss: 0.2415 - acc: 0.9265 - val_loss: 0.3313 - val_acc: 0.9085\n",
      "Epoch 48/50\n",
      "65931/65931 [==============================] - 13s 203us/step - loss: 0.2399 - acc: 0.9277 - val_loss: 0.3344 - val_acc: 0.9057\n",
      "Epoch 49/50\n",
      "41856/65931 [==================>...........] - ETA: 4s - loss: 0.2414 - acc: 0.927365931/65931 [==============================] - 13s 202us/step - loss: 0.2414 - acc: 0.9277 - val_loss: 0.3620 - val_acc: 0.9027\n",
      "Epoch 50/50\n",
      "65931/65931 [==============================] - 13s 202us/step - loss: 0.2349 - acc: 0.9288 - val_loss: 0.3409 - val_acc: 0.9090\n",
      "26032/26032 [==============================] - 5s 187us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.36984329247422465, 0.9061539643515673]"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_bn.compile(\"adam\", \"categorical_crossentropy\", metrics=['accuracy'])\n",
    "history_cnn_bn = cnn_bn.fit(x_train_images, y_train,\n",
    "                      batch_size=128, epochs=50, verbose=1, validation_split=.1)\n",
    "cnn_bn.evaluate(x_test_images, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YCBhW-cDi9F7"
   },
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ppNbQszmi0-h"
   },
   "outputs": [],
   "source": [
    "# conv,relu,conv,relu,pool, two layers\n",
    "from keras.layers import BatchNormalization\n",
    "cnn_bn_c = Sequential()\n",
    "cnn_bn_c.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 input_shape=input_shape))\n",
    "cnn_bn_c.add(Activation(\"relu\"))\n",
    "cnn_bn_c.add(Conv2D(32, kernel_size=(3, 3)))\n",
    "cnn_bn_c.add(Activation(\"relu\"))\n",
    "cnn_bn_c.add(BatchNormalization())\n",
    "cnn_bn_c.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_bn_c.add(Conv2D(32, (3, 3)))\n",
    "cnn_bn_c.add(Activation(\"relu\"))\n",
    "cnn_bn_c.add(Conv2D(32, (3, 3)))\n",
    "cnn_bn_c.add(Activation(\"relu\"))\n",
    "cnn_bn_c.add(BatchNormalization())\n",
    "cnn_bn_c.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_bn_c.add(Flatten())\n",
    "cnn_bn_c.add(Dense(64, activation='relu'))\n",
    "cnn_bn_c.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1788
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 755653,
     "status": "ok",
     "timestamp": 1524848912131,
     "user": {
      "displayName": "Selina Tang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "109686041627228452104"
     },
     "user_tz": 240
    },
    "id": "O7e3astFi6_o",
    "outputId": "98d5a4ae-77e0-4cf9-b81a-1ca201882e75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 65931 samples, validate on 7326 samples\n",
      "Epoch 1/50\n",
      "65931/65931 [==============================] - 17s 256us/step - loss: 0.7357 - acc: 0.7693 - val_loss: 0.6565 - val_acc: 0.8033\n",
      "Epoch 2/50\n",
      "56704/65931 [========================>.....] - ETA: 2s - loss: 0.3826 - acc: 0.885965931/65931 [==============================] - 15s 233us/step - loss: 0.3784 - acc: 0.8877 - val_loss: 0.4071 - val_acc: 0.8776\n",
      "Epoch 3/50\n",
      "65931/65931 [==============================] - 15s 233us/step - loss: 0.3077 - acc: 0.9080 - val_loss: 0.4123 - val_acc: 0.8746\n",
      "Epoch 4/50\n",
      "27520/65931 [===========>..................] - ETA: 8s - loss: 0.2544 - acc: 0.922565931/65931 [==============================] - 15s 230us/step - loss: 0.2669 - acc: 0.9203 - val_loss: 0.3726 - val_acc: 0.8848\n",
      "Epoch 5/50\n",
      "65931/65931 [==============================] - 15s 232us/step - loss: 0.2389 - acc: 0.9298 - val_loss: 0.3462 - val_acc: 0.8986\n",
      "Epoch 6/50\n",
      "20864/65931 [========>.....................] - ETA: 9s - loss: 0.1951 - acc: 0.943265931/65931 [==============================] - 15s 229us/step - loss: 0.2095 - acc: 0.9380 - val_loss: 0.3611 - val_acc: 0.8950\n",
      "Epoch 7/50\n",
      "65931/65931 [==============================] - 15s 229us/step - loss: 0.1900 - acc: 0.9437 - val_loss: 0.3939 - val_acc: 0.8900\n",
      "Epoch 8/50\n",
      "19072/65931 [=======>......................] - ETA: 10s - loss: 0.1501 - acc: 0.955565931/65931 [==============================] - 15s 229us/step - loss: 0.1681 - acc: 0.9497 - val_loss: 0.3610 - val_acc: 0.8965\n",
      "Epoch 9/50\n",
      "65931/65931 [==============================] - 15s 227us/step - loss: 0.1550 - acc: 0.9531 - val_loss: 0.3794 - val_acc: 0.8957\n",
      "Epoch 10/50\n",
      "18816/65931 [=======>......................] - ETA: 10s - loss: 0.1319 - acc: 0.961765931/65931 [==============================] - 15s 227us/step - loss: 0.1383 - acc: 0.9583 - val_loss: 0.3987 - val_acc: 0.8905\n",
      "Epoch 11/50\n",
      "65931/65931 [==============================] - 15s 228us/step - loss: 0.1222 - acc: 0.9636 - val_loss: 0.3960 - val_acc: 0.8972\n",
      "Epoch 12/50\n",
      "18560/65931 [=======>......................] - ETA: 10s - loss: 0.0961 - acc: 0.973265931/65931 [==============================] - 15s 227us/step - loss: 0.1100 - acc: 0.9674 - val_loss: 0.3937 - val_acc: 0.9019\n",
      "Epoch 13/50\n",
      "65931/65931 [==============================] - 15s 225us/step - loss: 0.0984 - acc: 0.9704 - val_loss: 0.4089 - val_acc: 0.9039\n",
      "Epoch 14/50\n",
      "18304/65931 [=======>......................] - ETA: 10s - loss: 0.0778 - acc: 0.977065931/65931 [==============================] - 15s 225us/step - loss: 0.0865 - acc: 0.9737 - val_loss: 0.4866 - val_acc: 0.8898\n",
      "Epoch 15/50\n",
      "65931/65931 [==============================] - 15s 225us/step - loss: 0.0807 - acc: 0.9748 - val_loss: 0.4692 - val_acc: 0.8967\n",
      "Epoch 16/50\n",
      "18304/65931 [=======>......................] - ETA: 10s - loss: 0.0635 - acc: 0.980865931/65931 [==============================] - 15s 225us/step - loss: 0.0721 - acc: 0.9783 - val_loss: 0.4910 - val_acc: 0.8941\n",
      "Epoch 17/50\n",
      "65931/65931 [==============================] - 15s 225us/step - loss: 0.0718 - acc: 0.9773 - val_loss: 0.4821 - val_acc: 0.8956\n",
      "Epoch 18/50\n",
      "18560/65931 [=======>......................] - ETA: 10s - loss: 0.0699 - acc: 0.978165931/65931 [==============================] - 15s 225us/step - loss: 0.0641 - acc: 0.9801 - val_loss: 0.5371 - val_acc: 0.8875\n",
      "Epoch 19/50\n",
      "65931/65931 [==============================] - 15s 227us/step - loss: 0.0552 - acc: 0.9831 - val_loss: 0.5264 - val_acc: 0.8961\n",
      "Epoch 20/50\n",
      "18304/65931 [=======>......................] - ETA: 10s - loss: 0.0433 - acc: 0.987965931/65931 [==============================] - 15s 224us/step - loss: 0.0513 - acc: 0.9846 - val_loss: 0.6322 - val_acc: 0.8735\n",
      "Epoch 21/50\n",
      "65931/65931 [==============================] - 15s 227us/step - loss: 0.0556 - acc: 0.9823 - val_loss: 0.5453 - val_acc: 0.8957\n",
      "Epoch 22/50\n",
      "18304/65931 [=======>......................] - ETA: 10s - loss: 0.0319 - acc: 0.990465931/65931 [==============================] - 15s 226us/step - loss: 0.0390 - acc: 0.9888 - val_loss: 0.6223 - val_acc: 0.8893\n",
      "Epoch 23/50\n",
      "65931/65931 [==============================] - 15s 228us/step - loss: 0.0496 - acc: 0.9843 - val_loss: 0.6138 - val_acc: 0.8930\n",
      "Epoch 24/50\n",
      "18304/65931 [=======>......................] - ETA: 10s - loss: 0.0370 - acc: 0.988765931/65931 [==============================] - 15s 225us/step - loss: 0.0425 - acc: 0.9868 - val_loss: 0.6389 - val_acc: 0.8842\n",
      "Epoch 25/50\n",
      "65931/65931 [==============================] - 15s 226us/step - loss: 0.0389 - acc: 0.9881 - val_loss: 0.5924 - val_acc: 0.8956\n",
      "Epoch 26/50\n",
      "18304/65931 [=======>......................] - ETA: 10s - loss: 0.0514 - acc: 0.984365931/65931 [==============================] - 15s 227us/step - loss: 0.0388 - acc: 0.9879 - val_loss: 0.6340 - val_acc: 0.8901\n",
      "Epoch 27/50\n",
      "65931/65931 [==============================] - 15s 226us/step - loss: 0.0356 - acc: 0.9890 - val_loss: 0.6210 - val_acc: 0.8935\n",
      "Epoch 28/50\n",
      "18304/65931 [=======>......................] - ETA: 10s - loss: 0.0310 - acc: 0.990565931/65931 [==============================] - 15s 228us/step - loss: 0.0375 - acc: 0.9885 - val_loss: 0.6766 - val_acc: 0.8913\n",
      "Epoch 29/50\n",
      "65931/65931 [==============================] - 15s 226us/step - loss: 0.0337 - acc: 0.9895 - val_loss: 0.7028 - val_acc: 0.8882\n",
      "Epoch 30/50\n",
      "18304/65931 [=======>......................] - ETA: 10s - loss: 0.0586 - acc: 0.981265931/65931 [==============================] - 15s 225us/step - loss: 0.0425 - acc: 0.9865 - val_loss: 0.6678 - val_acc: 0.8969\n",
      "Epoch 31/50\n",
      "65931/65931 [==============================] - 15s 226us/step - loss: 0.0270 - acc: 0.9921 - val_loss: 0.6679 - val_acc: 0.8927\n",
      "Epoch 32/50\n",
      "18304/65931 [=======>......................] - ETA: 10s - loss: 0.0189 - acc: 0.994865931/65931 [==============================] - 15s 226us/step - loss: 0.0261 - acc: 0.9928 - val_loss: 0.9303 - val_acc: 0.8634\n",
      "Epoch 33/50\n",
      "65931/65931 [==============================] - 15s 225us/step - loss: 0.0478 - acc: 0.9856 - val_loss: 0.6642 - val_acc: 0.8939\n",
      "Epoch 34/50\n",
      "18304/65931 [=======>......................] - ETA: 10s - loss: 0.0253 - acc: 0.993765931/65931 [==============================] - 15s 228us/step - loss: 0.0232 - acc: 0.9936 - val_loss: 0.6861 - val_acc: 0.8952\n",
      "Epoch 35/50\n",
      "65931/65931 [==============================] - 15s 226us/step - loss: 0.0235 - acc: 0.9935 - val_loss: 0.6989 - val_acc: 0.8971\n",
      "Epoch 36/50\n",
      "18304/65931 [=======>......................] - ETA: 10s - loss: 0.0223 - acc: 0.993065931/65931 [==============================] - 15s 228us/step - loss: 0.0299 - acc: 0.9905 - val_loss: 0.7176 - val_acc: 0.8907\n",
      "Epoch 37/50\n",
      "65931/65931 [==============================] - 15s 225us/step - loss: 0.0306 - acc: 0.9906 - val_loss: 0.8150 - val_acc: 0.8755\n",
      "Epoch 38/50\n",
      "18688/65931 [=======>......................] - ETA: 10s - loss: 0.0219 - acc: 0.992965931/65931 [==============================] - 15s 226us/step - loss: 0.0233 - acc: 0.9933 - val_loss: 0.7273 - val_acc: 0.8934\n",
      "Epoch 39/50\n",
      "65931/65931 [==============================] - 15s 227us/step - loss: 0.0289 - acc: 0.9915 - val_loss: 0.7904 - val_acc: 0.8870\n",
      "Epoch 40/50\n",
      "18560/65931 [=======>......................] - ETA: 10s - loss: 0.0316 - acc: 0.991465931/65931 [==============================] - 15s 226us/step - loss: 0.0266 - acc: 0.9921 - val_loss: 0.7472 - val_acc: 0.8969\n",
      "Epoch 41/50\n",
      "65931/65931 [==============================] - 15s 227us/step - loss: 0.0235 - acc: 0.9932 - val_loss: 0.7341 - val_acc: 0.8930\n",
      "Epoch 42/50\n",
      "18304/65931 [=======>......................] - ETA: 10s - loss: 0.0237 - acc: 0.992565931/65931 [==============================] - 15s 227us/step - loss: 0.0298 - acc: 0.9910 - val_loss: 0.7507 - val_acc: 0.8928\n",
      "Epoch 43/50\n",
      "65931/65931 [==============================] - 15s 226us/step - loss: 0.0256 - acc: 0.9926 - val_loss: 0.7920 - val_acc: 0.8900\n",
      "Epoch 44/50\n",
      "18304/65931 [=======>......................] - ETA: 10s - loss: 0.0246 - acc: 0.993265931/65931 [==============================] - 15s 225us/step - loss: 0.0203 - acc: 0.9945 - val_loss: 0.8490 - val_acc: 0.8886\n",
      "Epoch 45/50\n",
      "65931/65931 [==============================] - 15s 225us/step - loss: 0.0212 - acc: 0.9943 - val_loss: 0.7340 - val_acc: 0.8950\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18560/65931 [=======>......................] - ETA: 10s - loss: 0.0177 - acc: 0.995065931/65931 [==============================] - 15s 225us/step - loss: 0.0223 - acc: 0.9937 - val_loss: 0.7550 - val_acc: 0.8930\n",
      "Epoch 47/50\n",
      "65931/65931 [==============================] - 15s 229us/step - loss: 0.0346 - acc: 0.9897 - val_loss: 0.8504 - val_acc: 0.8867\n",
      "Epoch 48/50\n",
      "18304/65931 [=======>......................] - ETA: 10s - loss: 0.0191 - acc: 0.994765931/65931 [==============================] - 15s 226us/step - loss: 0.0225 - acc: 0.9938 - val_loss: 0.8405 - val_acc: 0.8862\n",
      "Epoch 49/50\n",
      "65931/65931 [==============================] - 15s 225us/step - loss: 0.0203 - acc: 0.9943 - val_loss: 0.8103 - val_acc: 0.8930\n",
      "Epoch 50/50\n",
      "18048/65931 [=======>......................] - ETA: 10s - loss: 0.0091 - acc: 0.997665931/65931 [==============================] - 15s 226us/step - loss: 0.0143 - acc: 0.9968 - val_loss: 0.7880 - val_acc: 0.8969\n",
      "26032/26032 [==============================] - 5s 188us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8574302408954443, 0.8910955746773203]"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_bn_c.compile(\"adam\", \"categorical_crossentropy\", metrics=['accuracy'])\n",
    "history_cnn_bn_c = cnn_bn_c.fit(x_train_images, y_train,\n",
    "                      batch_size=128, epochs=50, verbose=1, validation_split=.1)\n",
    "cnn_bn_c.evaluate(x_test_images, y_test)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Task3.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
